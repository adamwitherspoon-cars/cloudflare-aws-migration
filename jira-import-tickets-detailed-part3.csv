Issue Type,Summary,Description,Epic Link,Priority,Components,Labels,Story Points,Assignee,Reporter,Due Date
Story,Setup Automated Daily Processing,"**OBJECTIVE:** Implement fully automated daily processing pipeline for ongoing CloudFlare firewall data ingestion, processing, and storage with enterprise-grade reliability, monitoring, and operational excellence. **AUTOMATION ARCHITECTURE:** **Daily Processing Pipeline:** 1. **Data Discovery & Ingestion** - Automated detection of new daily data 2. **Parallel Processing Engine** - Multi-source concurrent processing 3. **Quality Assurance Pipeline** - Automated validation and quality checks 4. **Storage & Archival** - Intelligent data lifecycle management 5. **Monitoring & Alerting** - Comprehensive operational monitoring 6. **Error Handling & Recovery** - Automated failure recovery **DETAILED IMPLEMENTATION:** **1. Daily Processing Orchestrator (daily_orchestrator.py):** ```python import asyncio import boto3 import schedule import time from datetime import datetime, timedelta from typing import List, Dict, Optional import structlog from dataclasses import dataclass import json logger = structlog.get_logger() @dataclass class DailyProcessingJob: date: str sources: List[str] status: str = 'pending' # pending, running, completed, failed start_time: Optional[datetime] = None end_time: Optional[datetime] = None records_processed: int = 0 errors: List[str] = None class DailyProcessingOrchestrator: def __init__(self, config: Dict): self.config = config self.s3_client = boto3.client('s3') self.cloudwatch = boto3.client('cloudwatch') self.sns = boto3.client('sns') self.sources = ['2.ford', '3', '47'] self.processing_jobs: List[DailyProcessingJob] = [] async def start_daily_processing_service(self): \"\"\"Start the daily processing service with scheduling.\"\"\" logger.info(""Starting daily CloudFlare processing service"") # Schedule daily processing at 2 AM UTC schedule.every().day.at(""02:00"").do(self._trigger_daily_processing) # Schedule health checks every 15 minutes schedule.every(15).minutes.do(self._health_check) # Schedule cleanup weekly on Sunday at 3 AM schedule.every().sunday.at(""03:00"").do(self._weekly_cleanup) # Main service loop while True: schedule.run_pending() await asyncio.sleep(60) # Check every minute async def _trigger_daily_processing(self): \"\"\"Trigger daily processing for yesterday's data.\"\"\" yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d') logger.info(f""Triggering daily processing for {yesterday}"") job = DailyProcessingJob( date=yesterday, sources=self.sources.copy() ) self.processing_jobs.append(job) await self._execute_daily_job(job) async def _execute_daily_job(self, job: DailyProcessingJob): \"\"\"Execute daily processing job.\"\"\" job.status = 'running' job.start_time = datetime.now() job.errors = [] logger.info(f""Starting daily processing job for {job.date}"") try: # Phase 1: Data discovery available_sources = await self._discover_available_data(job.date) job.sources = [s for s in job.sources if s in available_sources] if not job.sources: logger.warning(f""No data available for {job.date}"") job.status = 'completed' return # Phase 2: Parallel processing tasks = [] for source in job.sources: task = asyncio.create_task( self._process_source_data(source, job.date) ) tasks.append(task) # Wait for all processing to complete results = await asyncio.gather(*tasks, return_exceptions=True) # Phase 3: Process results total_records = 0 for i, result in enumerate(results): source = job.sources[i] if isinstance(result, Exception): error_msg = f""Processing failed for {source}: {str(result)}"" job.errors.append(error_msg) logger.error(error_msg) else: total_records += result.get('records_processed', 0) logger.info(f""Completed processing for {source}: {result['records_processed']} records"") job.records_processed = total_records job.end_time = datetime.now() # Phase 4: Validation and quality checks validation_result = await self._validate_daily_processing(job) # Phase 5: Update status and send notifications if job.errors: job.status = 'failed' await self._send_failure_notification(job) else: job.status = 'completed' await self._send_success_notification(job) # Phase 6: Send metrics await self._send_daily_metrics(job) logger.info(f""Daily processing job completed for {job.date}: {job.status}"") except Exception as e: job.status = 'failed' job.errors.append(str(e)) job.end_time = datetime.now() logger.error(f""Daily processing job failed for {job.date}: {e}"") await self._send_failure_notification(job) async def _process_source_data(self, source: str, date: str) -> Dict: \"\"\"Process data for a single source and date.\"\"\" logger.info(f""Processing {source} for {date}"") start_time = time.time() try: # Step 1: Download data from source S3 temp_dir = f""/data/daily/{source}/{date}"" await self._download_daily_data(source, date, temp_dir) # Step 2: Process data output_dir = f""/data/processed/{source}"" processing_result = await self._process_daily_data( source, date, temp_dir, output_dir ) # Step 3: Upload processed data to target S3 await self._upload_daily_processed_data( source, date, processing_result['output_file'] ) # Step 4: Cleanup temporary data await self._cleanup_temp_data(temp_dir) processing_time = time.time() - start_time return { 'source': source, 'date': date, 'records_processed': processing_result['record_count'], 'processing_time': processing_time, 'output_file': processing_result['output_file'] } except Exception as e: logger.error(f""Failed to process {source}/{date}: {e}"") raise async def _validate_daily_processing(self, job: DailyProcessingJob) -> Dict: \"\"\"Validate daily processing results.\"\"\" validation_results = {} for source in job.sources: if source not in [error.split()[4] for error in job.errors]: # Source processed successfully output_file = f""/data/processed/{source}/firewall_logs_{source}_{job.date}.parquet"" validation_result = await self._validate_processed_file(source, job.date, output_file) validation_results[source] = validation_result return validation_results async def _send_daily_metrics(self, job: DailyProcessingJob): \"\"\"Send daily processing metrics to CloudWatch.\"\"\" duration = (job.end_time - job.start_time).total_seconds() if job.end_time and job.start_time else 0 success_rate = ((len(job.sources) - len(job.errors)) / len(job.sources)) * 100 if job.sources else 0 metrics = [ { 'MetricName': 'DailyProcessingDuration', 'Value': duration, 'Unit': 'Seconds', 'Dimensions': [{'Name': 'Date', 'Value': job.date}] }, { 'MetricName': 'DailyRecordsProcessed', 'Value': job.records_processed, 'Unit': 'Count', 'Dimensions': [{'Name': 'Date', 'Value': job.date}] }, { 'MetricName': 'DailyProcessingSuccessRate', 'Value': success_rate, 'Unit': 'Percent', 'Dimensions': [{'Name': 'Date', 'Value': job.date}] }, { 'MetricName': 'DailyProcessingErrors', 'Value': len(job.errors), 'Unit': 'Count', 'Dimensions': [{'Name': 'Date', 'Value': job.date}] } ] try: self.cloudwatch.put_metric_data( Namespace='CloudFlare/DailyProcessing', MetricData=metrics ) logger.info(f""Sent daily metrics for {job.date}"") except Exception as e: logger.error(f""Failed to send daily metrics: {e}"") ``` **2. Advanced Error Handling and Recovery:** ```python # error_recovery_advanced.py class AdvancedErrorRecovery: def __init__(self, config: Dict): self.config = config self.max_retries = config.get('max_retries', 3) self.retry_delays = [300, 900, 1800] # 5min, 15min, 30min self.dead_letter_queue = [] async def handle_processing_error(self, source: str, date: str, error: Exception, attempt: int = 1): \"\"\"Advanced error handling with intelligent retry logic.\"\"\" logger.error(f""Processing error for {source}/{date} (attempt {attempt}): {error}"") # Classify error type error_type = self._classify_error(error) # Determine if retry is appropriate if self._should_retry(error_type, attempt): delay = self._calculate_retry_delay(error_type, attempt) logger.info(f""Retrying {source}/{date} in {delay} seconds"") await asyncio.sleep(delay) try: return await self._retry_processing(source, date) except Exception as retry_error: return await self.handle_processing_error( source, date, retry_error, attempt + 1 ) else: # Move to dead letter queue for manual intervention self.dead_letter_queue.append({ 'source': source, 'date': date, 'error': str(error), 'error_type': error_type, 'attempts': attempt, 'timestamp': datetime.now().isoformat() }) await self._notify_manual_intervention_required(source, date, error) def _classify_error(self, error: Exception) -> str: \"\"\"Classify error type for appropriate handling.\"\"\" error_str = str(error).lower() if 'network' in error_str or 'timeout' in error_str: return 'network' elif 'memory' in error_str or 'out of memory' in error_str: return 'memory' elif 'permission' in error_str or 'access denied' in error_str: return 'permission' elif 'not found' in error_str or '404' in error_str: return 'missing_data' else: return 'unknown' def _should_retry(self, error_type: str, attempt: int) -> bool: \"\"\"Determine if error should be retried.\"\"\" if attempt > self.max_retries: return False # Don't retry permission errors if error_type == 'permission': return False # Don't retry missing data errors if error_type == 'missing_data': return False return True ``` **3. Intelligent Data Lifecycle Management:** ```python # data_lifecycle_manager.py class DataLifecycleManager: def __init__(self, s3_client): self.s3_client = s3_client self.bucket_name = 'cars-cloudflare-processed' async def manage_data_lifecycle(self): \"\"\"Manage data lifecycle and storage optimization.\"\"\" # Apply intelligent tiering await self._apply_intelligent_tiering() # Archive old processed data await self._archive_old_data() # Cleanup temporary processing data await self._cleanup_temp_data() # Optimize storage costs await self._optimize_storage_costs() async def _apply_intelligent_tiering(self): \"\"\"Apply S3 Intelligent Tiering for cost optimization.\"\"\" lifecycle_config = { 'Rules': [ { 'ID': 'ProcessedDataLifecycle', 'Status': 'Enabled', 'Filter': {'Prefix': 'processed/'}, 'Transitions': [ { 'Days': 30, 'StorageClass': 'STANDARD_IA' }, { 'Days': 90, 'StorageClass': 'GLACIER' }, { 'Days': 365, 'StorageClass': 'DEEP_ARCHIVE' } ] }, { 'ID': 'TempDataCleanup', 'Status': 'Enabled', 'Filter': {'Prefix': 'temp/'}, 'Expiration': {'Days': 7} }, { 'ID': 'LogsRetention', 'Status': 'Enabled', 'Filter': {'Prefix': 'logs/'}, 'Expiration': {'Days': 90} } ] } try: self.s3_client.put_bucket_lifecycle_configuration( Bucket=self.bucket_name, LifecycleConfiguration=lifecycle_config ) logger.info(""Applied S3 lifecycle configuration"") except Exception as e: logger.error(f""Failed to apply lifecycle configuration: {e}"") ``` **4. Comprehensive Monitoring Dashboard:** ```json { ""widgets"": [ { ""type"": ""metric"", ""properties"": { ""metrics"": [ [ ""CloudFlare/DailyProcessing"", ""DailyProcessingSuccessRate"" ] ], ""period"": 86400, ""stat"": ""Average"", ""region"": ""us-east-1"", ""title"": ""Daily Processing Success Rate"", ""yAxis"": { ""left"": { ""min"": 0, ""max"": 100 } } } }, { ""type"": ""metric"", ""properties"": { ""metrics"": [ [ ""CloudFlare/DailyProcessing"", ""DailyRecordsProcessed"" ] ], ""period"": 86400, ""stat"": ""Sum"", ""region"": ""us-east-1"", ""title"": ""Daily Records Processed"" } }, { ""type"": ""metric"", ""properties"": { ""metrics"": [ [ ""CloudFlare/DailyProcessing"", ""DailyProcessingDuration"" ] ], ""period"": 86400, ""stat"": ""Average"", ""region"": ""us-east-1"", ""title"": ""Daily Processing Duration (seconds)"" } }, { ""type"": ""log"", ""properties"": { ""query"": ""SOURCE 'cloudflare-daily-processing' | fields @timestamp, source, date, status, records_processed | filter status = 'completed' | sort @timestamp desc | limit 20"", ""region"": ""us-east-1"", ""title"": ""Recent Daily Processing Jobs"" } } ] } ``` **5. Operational Runbook Integration:** ```yaml # operational_runbook.yaml daily_processing: schedule: time: ""02:00 UTC"" timezone: ""UTC"" frequency: ""daily"" timeout: ""4 hours"" # Maximum processing time allowed monitoring: success_rate_threshold: 95 # Alert if success rate < 95% processing_time_threshold: 7200 # Alert if processing > 2 hours record_count_variance: 20 # Alert if daily records vary > 20% alerts: success_rate_low: severity: ""warning"" notification: ""email"" recipients: [""data-team@company.com""] processing_timeout: severity: ""critical"" notification: [""email"", ""sms""] recipients: [""oncall@company.com""] no_data_available: severity: ""warning"" notification: ""email"" recipients: [""data-team@company.com""] recovery_procedures: processing_failure: - ""Check CloudWatch logs for error details"" - ""Verify source S3 bucket accessibility"" - ""Check EC2 instance health and resources"" - ""Restart processing service if needed"" - ""Manual intervention for persistent failures"" data_quality_issues: - ""Run data validation pipeline"" - ""Compare with historical patterns"" - ""Check source data quality"" - ""Alert data engineering team"" resource_exhaustion: - ""Check EC2 instance metrics"" - ""Scale up instance if needed"" - ""Clear temporary data if disk full"" - ""Optimize processing parameters"" ``` **ACCEPTANCE CRITERIA:** - [ ] Daily processing service deployed and running - [ ] Automated scheduling configured (2 AM UTC daily) - [ ] Multi-source parallel processing implemented - [ ] Comprehensive error handling and recovery - [ ] Data quality validation integrated - [ ] CloudWatch monitoring and alerting active - [ ] S3 lifecycle management configured - [ ] Operational runbook documented - [ ] Health check monitoring every 15 minutes - [ ] Weekly cleanup automation implemented - [ ] Performance metrics tracking - [ ] Cost optimization features enabled - [ ] Dead letter queue for failed jobs - [ ] Manual intervention procedures documented **OPERATIONAL TARGETS:** - **Processing Time**: Complete daily processing within 2 hours - **Success Rate**: >95% daily processing success rate - **Data Freshness**: Process previous day's data by 6 AM UTC - **Error Recovery**: Automatic retry within 30 minutes - **Resource Utilization**: <80% CPU, <85% memory during processing - **Cost Efficiency**: Maintain daily processing cost <$50/day **MONITORING AND ALERTING:** **Real-time Alerts:** - Processing failures (immediate) - Resource exhaustion (5 minutes) - Data quality issues (immediate) - Processing timeout (2 hours) **Daily Reports:** - Processing summary and metrics - Data volume and quality statistics - Cost analysis and optimization opportunities - Performance trends and recommendations **Weekly Reviews:** - Processing reliability analysis - Cost optimization assessment - Capacity planning recommendations - Operational improvements identification **DISASTER RECOVERY:** - **Backup Processing**: Secondary processing capability - **Data Recovery**: Point-in-time recovery from S3 - **Service Recovery**: Automated service restart procedures - **Manual Override**: Emergency manual processing procedures",CloudFlare Data Processing Migration to AWS,High,Development,automation daily-processing,13,,,
Story,Create Documentation and Handover,"**OBJECTIVE:** Create comprehensive technical documentation, operational procedures, and knowledge transfer materials for CloudFlare AWS migration to ensure smooth handover to operations team and long-term maintainability. **DOCUMENTATION SCOPE:** **Documentation Deliverables:** 1. **Technical Architecture Documentation** - System design and data flow 2. **Operational Runbooks** - Day-to-day operations and troubleshooting 3. **Deployment Guides** - Infrastructure setup and configuration 4. **Monitoring and Alerting Guide** - Observability and incident response 5. **Cost Management Documentation** - Budget monitoring and optimization 6. **Knowledge Transfer Materials** - Training materials and handover sessions **DETAILED DOCUMENTATION STRUCTURE:** **1. Technical Architecture Documentation (architecture.md):** ```markdown # CloudFlare AWS Migration - Technical Architecture ## Overview The CloudFlare AWS Migration project migrates firewall log processing from local infrastructure to AWS Cars Platform Security account for enterprise-scale data processing. ### System Architecture ```mermaid graph TB A[DI Security S3<br/>cloudflare-logs-di] -->|Cross-Account Access| B[Cars Platform Security<br/>EC2 Processing Instance] B --> C[Cars Platform Security S3<br/>cars-cloudflare-processed] B --> D[CloudWatch Monitoring] B --> E[SNS Alerting] C --> F[Data Analytics] D --> G[Operations Dashboard] E --> H[On-Call Team] ``` ### Data Flow 1. **Source Data**: CloudFlare firewall logs in DI Security S3 bucket 2. **Processing**: EC2 instance with Polars/Python processing 3. **Output**: Processed parquet files in Cars Platform Security S3 4. **Monitoring**: CloudWatch metrics and logs 5. **Alerting**: SNS notifications for failures ### Key Components #### EC2 Processing Instance - **Instance Type**: r6i.4xlarge (16 vCPUs, 128 GiB RAM) - **Storage**: 1TB gp3 EBS volume for data processing - **Operating System**: Amazon Linux 2023 - **Software Stack**: Python 3.11, UV package manager, Polars #### S3 Buckets **Source Bucket (DI Security Account)**: - Bucket: `s3://cloudflare-logs-di/logs/firewall/di-websites/` - Access: Cross-account IAM role - Data Format: Compressed .gz files organized by date **Target Bucket (Cars Platform Security)**: - Bucket: `s3://cars-cloudflare-processed/` - Structure: `/processed/{source}/firewall_logs_{source}_{date}.parquet` - Lifecycle: Intelligent Tiering enabled #### Processing Pipeline **Daily Processing Flow**: 1. Data Discovery: Identify new daily data 2. Download: Transfer from source S3 to EC2 3. Process: Transform with Polars (cleaning, analytics, parquet conversion) 4. Validate: Data quality and integrity checks 5. Upload: Store processed data in target S3 6. Cleanup: Remove temporary files **Data Sources**: - `2.ford`: Ford firewall events - `3`: Unknown source - `47`: Largest dataset ### Performance Specifications - **Processing Speed**: >15,000 records/second - **Daily Throughput**: Process previous day's data within 2 hours - **Concurrent Processing**: Up to 4 parallel source processing - **Memory Usage**: <85% of available RAM - **Storage**: Automatic lifecycle management ### Security Configuration #### IAM Roles **DI Security Account Role**: `CloudFlareDataReader` - Permissions: S3 read access to cloudflare-logs-di bucket - Trust Policy: Allow Cars Platform Security account to assume **Cars Platform Security Role**: `CloudFlareDataProcessor` - Permissions: Cross-account assume role + S3 full access to target bucket - Attached to: EC2 instance profile #### Network Security - **Security Group**: Minimal access (SSH from bastion only) - **VPC**: Default VPC with private subnet - **Encryption**: S3 server-side encryption (AES-256) ### Monitoring and Alerting #### CloudWatch Metrics **Infrastructure Metrics**: - CPU Utilization (alert >80%) - Memory Usage (alert >85%) - Disk Usage (alert >90%) **Application Metrics**: - Processing Duration - Records Processed - Error Rates - Data Quality Scores #### Alerting Thresholds **Warning Level**: - CPU >80% for 10 minutes - Memory >85% for 5 minutes - Processing errors detected **Critical Level**: - CPU >95% for 5 minutes - No processing activity for 25 hours - Processing failure rate >10% ``` **2. Operational Runbook (operations.md):** ```markdown # CloudFlare Processing - Operational Runbook ## Daily Operations ### Morning Checklist (6 AM UTC) 1. **Verify Daily Processing Completion** ```bash # Check processing status for yesterday YESTERDAY=$(date -d ""yesterday"" +%Y%m%d) aws logs filter-log-events \ --log-group-name cloudflare-processing \ --start-time $(date -d ""yesterday 00:00"" +%s)000 \ --filter-pattern ""Processing completed for $YESTERDAY"" ``` 2. **Review Processing Metrics** - Check CloudWatch dashboard for success rates - Verify record counts are within expected ranges - Review any error notifications 3. **Validate Data Quality** ```bash # Run data validation for yesterday's processing cd /opt/cloudflare-processor uv run python -m cloudflare_processor.cli.validate \ --date $YESTERDAY \ --all-sources ``` ### Weekly Operations ### Monday Morning Review 1. **Performance Analysis** - Review weekly processing performance trends - Analyze cost optimization opportunities - Check resource utilization patterns 2. **Capacity Planning** - Review storage usage and growth trends - Assess EC2 instance performance - Plan for any scaling needs ### Troubleshooting Procedures #### Processing Failures **Symptom**: Daily processing job failed **Investigation Steps**: 1. Check CloudWatch logs for error details 2. Verify EC2 instance health 3. Check S3 bucket accessibility 4. Review resource utilization **Resolution**: ```bash # Restart processing service sudo systemctl restart cloudflare-processor # Manual processing trigger cd /opt/cloudflare-processor ./scripts/process_daily.sh ``` #### High Memory Usage **Symptom**: Memory usage >90% **Investigation**: 1. Check running processes: `top -o %MEM` 2. Review processing job sizes 3. Check for memory leaks **Resolution**: ```bash # Clear system cache sudo sync && sudo sysctl vm.drop_caches=3 # Restart processing with smaller batch size # Edit config to reduce concurrent processing ``` #### S3 Access Issues **Symptom**: S3 access denied errors **Investigation**: 1. Verify IAM role permissions 2. Check cross-account trust relationships 3. Test S3 access manually **Resolution**: ```bash # Test S3 access aws s3 ls s3://cloudflare-logs-di/logs/firewall/di-websites/ --profile di-security aws s3 ls s3://cars-cloudflare-processed/ --profile cars-platform-security # Refresh IAM credentials aws sts get-caller-identity --profile cars-platform-security ``` ### Emergency Procedures #### Complete Processing Failure **Immediate Actions**: 1. Alert on-call team 2. Check system health 3. Attempt automatic recovery **Recovery Steps**: 1. Identify root cause 2. Implement fix 3. Resume processing from last checkpoint 4. Validate data integrity **Communication**: - Update incident channel - Notify stakeholders of impact - Provide regular status updates ### Maintenance Procedures #### Monthly Maintenance **First Saturday of each month**: 1. **System Updates** ```bash # Update system packages sudo yum update -y # Update Python dependencies cd /opt/cloudflare-processor uv sync --upgrade ``` 2. **Log Cleanup** ```bash # Clean old logs find /data/logs -name ""*.log"" -mtime +30 -delete ``` 3. **Performance Optimization** - Review and optimize processing parameters - Update resource allocation if needed - Clean up unused data #### Quarterly Reviews **Every 3 months**: 1. **Architecture Review** - Assess system performance - Identify optimization opportunities - Plan capacity upgrades 2. **Cost Optimization** - Review AWS costs and usage - Implement cost-saving measures - Update Reserved Instance strategy 3. **Security Review** - Review IAM permissions - Update security configurations - Conduct security assessment ``` **3. Deployment Guide (deployment.md):** ```markdown # CloudFlare AWS Migration - Deployment Guide ## Prerequisites ### AWS Account Access - Cars Platform Security account (813388701013) with Administrator access - DI Security account (253296570627) with S3 read access - AWS CLI configured with appropriate profiles ### Required Tools - AWS CLI v2.x - Terraform or CloudFormation - Python 3.11+ - UV package manager ## Infrastructure Deployment ### Step 1: IAM Roles Setup **DI Security Account (253296570627)**: ```json { ""Version"": ""2012-10-17"", ""Statement"": [{ ""Effect"": ""Allow"", ""Principal"": { ""AWS"": ""arn:aws:iam::813388701013:role/CloudFlareDataProcessor"" }, ""Action"": ""sts:AssumeRole"", ""Condition"": { ""StringEquals"": { ""sts:ExternalId"": ""cloudflare-migration-2025"" } } }] } ``` **Cars Platform Security Account (813388701013)**: ```bash # Create IAM role aws iam create-role \ --role-name CloudFlareDataProcessor \ --assume-role-policy-document file://ec2-trust-policy.json # Attach policies aws iam attach-role-policy \ --role-name CloudFlareDataProcessor \ --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess aws iam put-role-policy \ --role-name CloudFlareDataProcessor \ --policy-name CrossAccountAssumeRole \ --policy-document file://cross-account-policy.json ``` ### Step 2: S3 Bucket Creation ```bash # Create processing bucket aws s3 mb s3://cars-cloudflare-processed --region us-east-1 # Apply bucket policy aws s3api put-bucket-policy \ --bucket cars-cloudflare-processed \ --policy file://bucket-policy.json # Configure lifecycle management aws s3api put-bucket-lifecycle-configuration \ --bucket cars-cloudflare-processed \ --lifecycle-configuration file://lifecycle-config.json ``` ### Step 3: EC2 Instance Launch ```bash # Launch EC2 instance aws ec2 run-instances \ --image-id ami-0abcdef1234567890 \ --instance-type r6i.4xlarge \ --key-name cloudflare-processing-keypair \ --security-group-ids sg-0123456789abcdef0 \ --iam-instance-profile Name=CloudFlareDataProcessor \ --user-data file://user-data.sh \ --block-device-mappings file://block-device-mappings.json ``` ### Step 4: Application Deployment ```bash # SSH to EC2 instance ssh -i cloudflare-processing-keypair.pem ec2-user@<instance-ip> # Clone application repository git clone https://github.com/company/cloudflare-processor.git cd cloudflare-processor # Install dependencies uv sync # Configure application cp config/production.yaml.template config/production.yaml # Edit configuration as needed # Install as system service sudo cp scripts/cloudflare-processor.service /etc/systemd/system/ sudo systemctl enable cloudflare-processor sudo systemctl start cloudflare-processor ``` ## Configuration Management ### Environment Configuration **Production Configuration (config/production.yaml)**: ```yaml processing: sources: - ""2.ford"" - ""3"" - ""47"" max_concurrent_tasks: 4 chunk_size: 1000000 memory_limit_gb: 100 aws: source_bucket: ""cloudflare-logs-di"" target_bucket: ""cars-cloudflare-processed"" region: ""us-east-1"" cross_account_role: ""arn:aws:iam::253296570627:role/CloudFlareDataReader"" monitoring: cloudwatch_namespace: ""CloudFlare/Processing"" log_level: ""INFO"" metrics_interval: 300 validation: enabled: true quality_threshold: 95.0 integrity_checks: true ``` ### Monitoring Setup ```bash # Create CloudWatch dashboard aws cloudwatch put-dashboard \ --dashboard-name ""CloudFlare-Processing"" \ --dashboard-body file://dashboard-config.json # Create CloudWatch alarms aws cloudwatch put-metric-alarm \ --alarm-name ""CloudFlare-Processing-HighCPU"" \ --alarm-description ""CPU usage is above 80%"" \ --metric-name CPUUtilization \ --namespace AWS/EC2 \ --statistic Average \ --period 300 \ --threshold 80 \ --comparison-operator GreaterThanThreshold \ --evaluation-periods 2 ``` ## Verification and Testing ### Deployment Verification ```bash # Test AWS access aws sts get-caller-identity --profile cars-platform-security # Test cross-account S3 access aws s3 ls s3://cloudflare-logs-di/logs/firewall/di-websites/ --profile di-security # Test processing pipeline cd /opt/cloudflare-processor uv run python -m cloudflare_processor.cli.main test-connection # Run sample processing test ./scripts/test_processing.sh ``` ### Performance Testing ```bash # Run performance benchmark ./scripts/performance_test.sh # Load testing with sample data ./scripts/load_test.sh --duration 1h --concurrency 4 ``` ## Rollback Procedures ### Emergency Rollback If deployment fails: 1. **Stop Processing Service** ```bash sudo systemctl stop cloudflare-processor ``` 2. **Revert Configuration** ```bash git checkout HEAD~1 config/production.yaml sudo systemctl restart cloudflare-processor ``` 3. **Verify Rollback** ```bash # Check service status sudo systemctl status cloudflare-processor # Test basic functionality ./scripts/health_check.sh ``` ``` **4. Knowledge Transfer Materials:** **Training Presentation Outline:** 1. **System Overview** (15 minutes) - Architecture and data flow - Key components and technologies 2. **Daily Operations** (20 minutes) - Monitoring dashboards - Routine checks and procedures 3. **Troubleshooting** (25 minutes) - Common issues and solutions - Escalation procedures 4. **Hands-on Session** (30 minutes) - Live system walkthrough - Practice common operations **Handover Checklist:** - [ ] Technical documentation reviewed and approved - [ ] Operational runbooks tested and validated - [ ] Deployment procedures documented and verified - [ ] Monitoring and alerting configured and tested - [ ] Training sessions completed for operations team - [ ] Emergency contact information updated - [ ] Access credentials transferred securely - [ ] Knowledge transfer sessions conducted - [ ] Post-handover support schedule established **ACCEPTANCE CRITERIA:** - [ ] Complete technical architecture documentation - [ ] Comprehensive operational runbooks with troubleshooting procedures - [ ] Step-by-step deployment guide tested and validated - [ ] Monitoring and alerting documentation - [ ] Cost management and optimization guide - [ ] Knowledge transfer materials created and delivered - [ ] Training sessions conducted for operations team - [ ] Emergency procedures documented and tested - [ ] Handover checklist completed and signed off - [ ] Post-deployment support plan established - [ ] Documentation stored in accessible knowledge base - [ ] Regular documentation update process established **DOCUMENTATION STANDARDS:** - **Format**: Markdown with diagrams (Mermaid) - **Version Control**: Git repository with change tracking - **Review Process**: Technical review + operations team approval - **Update Schedule**: Quarterly reviews and updates - **Accessibility**: Centralized knowledge base with search capability **SUCCESS METRICS:** - **Documentation Completeness**: 100% of required documents delivered - **Knowledge Transfer**: Operations team can independently manage system - **Incident Response**: <30 minutes to access relevant documentation - **Onboarding Time**: New team members productive within 2 days - **Documentation Usage**: Regular access and updates by operations team",CloudFlare Data Processing Migration to AWS,Medium,Documentation,documentation handover,5,,,
